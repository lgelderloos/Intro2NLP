{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR evaluation\n",
    "\n",
    "Copyright CLTL, VU Amsterdam\n",
    "\n",
    "Prepared by Lieke Gelderloos, April 2021\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing prerequities\n",
    "\n",
    "### SpeechRecognition\n",
    "\n",
    "The Python package [SpeechRecognition](https://github.com/Uberi/speech_recognition) provides access to several different ASR systems. You can install it via the terminal using pip.\n",
    "\n",
    "`pip install SpeechRecognition`\n",
    "\n",
    "If you are using Anaconda, you can install it using conda.\n",
    "\n",
    "`conda install -c conda-forge SpeechRecognition`\n",
    "\n",
    "The systems this package gives access to are some of the major commercially available systems, that can be used at scale (you could use them to build ASR into an app, for example). For this reason, you usually have to sign up for an account (not necessarily paid - there are usually different options depending on what you want to use the system for and how intensively). There are two exceptions: Google Speech Recognition, for which a 'default' API key is included in the SpeechRecognition library, and CMU Sphinx, which is an offline system. Since the latter runs on the user's system, it requires downloading the models involved and a rather complicated installation process (if you want to give it a try, see the [information about PocketSphinx in the README of SpeechRecognition](https://github.com/Uberi/speech_recognition#pocketsphinx-python-for-sphinx-users)). For the purpose of this tutorial we will use Google Speech Recognition as it should work out-of-the-box. Note that it is subject to a 'fair use' policy, so if you want to use ASR more intensely (say to use as input for an app), you will need to obtain your own API key.\n",
    "\n",
    "### PyAudio\n",
    "\n",
    "Since we are going to be working with our own speech, we need to be able to use the microphone to record it. To be able to use the microphone for input, install the package PyAudio using either pip or conda.\n",
    "\n",
    "`pip install PyAudio`\n",
    "\n",
    "`conda install -c conda-forge PyAudio`\n",
    "\n",
    "### Testing if the abovementioned packages work\n",
    "\n",
    "On the command line, run \n",
    "\n",
    "`python -m speech_recognition`\n",
    "\n",
    "and say something when prompted.\n",
    "\n",
    "### JiWER\n",
    "\n",
    "This is a package we will use for evaluation.\n",
    "\n",
    "`pip install jiwer`\n",
    "\n",
    "It is not readily available through conda; either you will have to use `conda-build` or you can install it using pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording some data\n",
    "\n",
    "Let's record the following sentences (note, insert your (nick)name into the second sentence!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\"Hello world!\",\n",
    "            \"Hello, my name is ###.\", # insert your (nick)name in place of the ###\n",
    "            \"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\",\n",
    "            \"Bilbo Baggins was a hobbit who lived in the Shire during the Third Age.\",\n",
    "            \"Wreck a nice beach.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will loop through the sentences and prompt the user (you!) to say the sentence, and record 5 seconds of audio for each. We will store the audio in a nested dictionary test_sentences. The dictionaries include an `'audio'` field and a `'ground_truth'` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please say:\n",
      "Hello world!\n",
      "Please say:\n",
      "Hello, my name is ###.\n",
      "Please say:\n",
      "How much wood would a woodchuck chuck if a woodchuck could chuck wood?\n",
      "Please say:\n",
      "Bilbo Baggins was a hobbit who lived in the Shire during the Third Age.\n",
      "Please say:\n",
      "Wreck a nice beach.\n",
      "Done recording!\n"
     ]
    }
   ],
   "source": [
    "rec = speech_recognition.Recognizer() # instantiate the Recognizer object\n",
    "\n",
    "def record_sentences(sentences, rec):\n",
    "    recorded = []\n",
    "    for sentence in sentences:\n",
    "        print(f\"Please say:\\n{sentence}\")\n",
    "        with speech_recognition.Microphone() as source:\n",
    "            audio_data = rec.record(source, duration=5) # record 5 seconds of speech\n",
    "        recorded.append({'audio': audio_data, 'ground_truth': sentence})\n",
    "    print('Done recording!')\n",
    "    return recorded\n",
    "\n",
    "recordings = record_sentences(test_sentences, rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "hello my name is Luka\n",
      "how much wood would a woodchuck chuck if a woodchuck could chuck wood\n",
      "Google meghan's Mother Hubbard who lived in a shower during the Third Age\n",
      "recognise speech\n"
     ]
    }
   ],
   "source": [
    "def transcribe_sentences(recordings):\n",
    "    for sentence in recordings:\n",
    "        try:\n",
    "            transcription = rec.recognize_google(sentence['audio']) # use the google ASR to transcribe the recording\n",
    "        except:\n",
    "            print(f\"transcription failed for {sentence['ground_truth']}\")\n",
    "            transcription = \"\" # if speech recognition fails, return an empty string instead of a transcription\n",
    "        print(transcription)\n",
    "        sentence['google_transcript'] = transcription # write the transcriptions to a transcription field in the dictionary\n",
    "        \n",
    "transcribe_sentences(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did the transcription go? Do you notice any mistakes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "## Word Error Rate\n",
    "ASR systems are typically evaluated using the Word Error Rate (WER) between the ASR output and ground-truth transcriptions. To calculate WER, you count the number of words in the ASR output that are inserted, deleted, and substituted with respect to the ground truth transcription, and divide this by the total number of words in the ground truth transcription. \n",
    "\n",
    "$WER = \\frac{S + D + I}{N}$\n",
    "\n",
    "where:<br>\n",
    "$S$ is the number of substituted words<br>\n",
    "$D$ is the number of deleted words<br>\n",
    "$I$ is the number of inserted words<br>\n",
    "$N$ is the length of the ground truth in words<br>\n",
    "\n",
    "\n",
    "You always count the minimum required edits; e.g. if a word is replaced by another word, you count that as one edit (a substitution), rather than as two edits (one insertion and one deletion). The lower the word eror rate, the better; if there are no errors, WER will be 0. \n",
    "\n",
    "Note that it is possible for the WER to exceed 1. $S+D$ will never exceed N, since they are tied to the words in the original sentence: you can only insert or delete words that are actually in a sentence. $I$, however, is not tied to $N$, since the number of insertions does not depend on the number of original words in the sentence. Therefore, $S+D+I$ may exceed $N$, meaning $WER$ may exceed 1!\n",
    "\n",
    "### Word Error Rate by hand\n",
    "For one of the test sentences in which the ASR made ome mistakes, find the insertions, deletions and substitutions, and then calculate the WER. Ignore punctuation and capitalization.\n",
    "\n",
    "In the unlikely event that ASR went perfectly for every sentence, work through the following example:\n",
    "\n",
    "Ground truth: \n",
    "`Bilbo Baggins was a hobbit who lived in the Shire during the Third Age.` <br>\n",
    "Transcription: \n",
    "`double bangs with a hobbit who lived in the shower during the Third Age.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insertions: <br>\n",
    "Deletions: <br>\n",
    "Substitutions: <br>\n",
    "\n",
    "Number of words in the ground truth:\n",
    "    \n",
    "WER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Error Rate automatically\n",
    "While the above calculation may look simple, that is because your brain has done the difficult work intuitively: identifying the minimum required insertions, deletions, and substitutions. Implementing this is not quite as straightforward, as it requires an alignment between the ground truth transcription and the recognized speech. If the ASR omits a word at the start of the sentence, but correctly identifies the rest of the words, we want to punish it only for omitting the first word, and not for the rest of the words, as we can align them to the ground truth. \n",
    "\n",
    "In order to calculate the WER, then, we need to find the optimal alignment between the word sequence in the ground truth and our ASR output. Perhaps you have heard about Levenshtein distance before, a metric to calculate the distance between two sequences. This is what the WER is based on (basically, WER is Levenshtein distance divided by the length of the ground truth sentence) It can be implemented in different ways (see the Wikipedia page if interested in the algorithm).\n",
    "\n",
    "We will use the function `wer()` from [JiWER](https://pypi.org/project/jiwer/) to calculate word error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recordings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ce67fa07c63e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjiwer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecordings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjiwer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ground_truth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'google_transcript'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recordings' is not defined"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "for sentence in recordings:\n",
    "    print(jiwer.wer(sentence['ground_truth'], sentence['google_transcript']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these the values you expected?\n",
    "\n",
    "Perhaps not!\n",
    "\n",
    "JiWER's `wer()` is case-sensistive, meaning that it punishes ASR for transcibing 'Hello' as 'hello'. Also, `wer()` only strips out `.`and `,` - any other punctuation is left in. ASR's are thus punished for not transcribing e.g. exclamation marks.\n",
    "Let's clean the punctuation from both sentences before calculating WER, and also lowercase them so that our WER becomes case-insensitive. Note that this is a choice: perhaps you care whether your model differentiates between the word 'chase' and the given name 'Chase'; and perhaps you want your ASR to recognize question-intonation. You might make different choices then. \n",
    "\n",
    "As a side note, JiWER also contains tools to do these types of regularization before calculating WER; you can check the description of different `transformation`s in the [documentation](https://pypi.org/project/jiwer/) if you want to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.25\n",
      "0.0\n",
      "0.5\n",
      "1.0\n",
      "Average WER: 0.35\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    # remove punctuation\n",
    "    exclude = set(string.punctuation) # we want to remove all characters from the string.punctuation class\n",
    "    clean_string = ''.join(ch for ch in sentence if ch not in exclude) # if the character is not in string.punctuation, we keep it\n",
    "    # return lowercased\n",
    "    return clean_string.lower()\n",
    "    \n",
    "def wer_clean(ground_truth, asr_result):\n",
    "    wer = jiwer.wer(clean_sentence(ground_truth), clean_sentence(asr_result))\n",
    "    return wer\n",
    "\n",
    "def calculate_wers(recordings):\n",
    "    wers = []\n",
    "    for sentence in recordings:\n",
    "        wer = wer_clean(sentence['ground_truth'], sentence['google_transcript'])\n",
    "        print(wer)\n",
    "        wers.append(wer)\n",
    "    return(wers)\n",
    "    \n",
    "print(\"Average WER:\", np.mean(calculate_wers(recordings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial conditions\n",
    "\n",
    "Let's make the ASR's task a bit more challenging. Think of some suboptimal conditions for ASR: e.g. sit next to a noisy fan; speak very fast or slow, or in a non-standard accent. Record the sentences again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heywood\n",
      "transcription failed for Hello, my name is ###.\n",
      "\n",
      "transcription failed for How much wood would a woodchuck chuck if a woodchuck could chuck wood?\n",
      "\n",
      "women's onesie\n",
      "speech\n"
     ]
    }
   ],
   "source": [
    "#noisy_recordings = record_sentences(test_sentences, rec)\n",
    "transcribe_sentences(noisy_recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "Average WER on noisy speech: 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "print(\"Average WER on noisy speech:\", np.mean(calculate_wers(noisy_recordings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the assignment is meant to be done together with your group members.\n",
    "\n",
    "A) Compare the average WER between the members of your group, in the clean and the adversarial conditions separately. Does the ASR perform equally well for all members of your group? If not, can you think of reasons why that might be? Consider different factors such as characteristics of your voices, accents, and recording conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) A HMM-based system consists of a phonetic model, the pronunciation lexicon, and the language model. Try to find a mistake that is likely attributable to each of these components, and explain how it might have occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) Try to find a phonetic error and a lexical error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
